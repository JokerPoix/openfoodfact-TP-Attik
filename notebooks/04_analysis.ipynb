{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba7aba4",
   "metadata": {},
   "source": [
    "# 📊 04 - Analyse de Données avec Spark\n",
    "Ce notebook a pour objectif de fournir des données d'analyse à partir des données déjà transformées, nettoyées et enrichies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227980a4-00b6-4f3b-b6b3-fd51250c1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Stoppe toute session existante\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Recréation SparkSession en local, FS local et driver binding fixe\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"03_Enrichment\")\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", \"file:///\")\n",
    "        .config(\"spark.driver.host\", \"127.0.0.1\")\n",
    "        .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "        .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower, trim, count\n",
    "import os\n",
    "\n",
    "# 1. Chargement\n",
    "path = os.path.abspath(os.path.join(os.getcwd(), \"../data/step3_enriched_csv\"))\n",
    "df_enriched = spark.read.option(\"header\", \"true\").option(\"sep\", \";\").csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84938c7-9644-4a48-a095-6964c53a5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marques les plus fréquentes\n",
    "top_brands = df_enriched.groupBy(\"brands\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .filter(col(\"brands\").isNotNull() & (col(\"brands\") != \"\")) \\\n",
    "    .limit(30)\n",
    "\n",
    "# Sauvegarde pour la visualisation\n",
    "top_brands.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/top_brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54ef92-9ad3-4035-a391-63241d896d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pays les plus fréquents\n",
    "top_countries = df_enriched.groupBy(\"country\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"count\", ascending=False) \\\n",
    "    .filter(col(\"country\").isNotNull() & (col(\"country\") != \"\")) \\\n",
    "    .limit(20)\n",
    "\n",
    "top_countries.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/top_countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb50a5-ae14-48d1-9927-24ec80d0d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Moyenne score_env_composite_flexible (impact environnementale) par pays (classés par fréquence d’apparition)\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Fréquence des pays\n",
    "country_freq = df_enriched.groupBy(\"country\").count()\n",
    "\n",
    "# Moyenne des scores environnementaux\n",
    "score_by_country = df_enriched.groupBy(\"country\") \\\n",
    "    .agg(F.avg(\"score_env_composite_flexible\").alias(\"avg_score_env_composite_flexible\"))\n",
    "\n",
    "# Jointure et tri par fréquence décroissante\n",
    "result_country = score_by_country.join(country_freq, on=\"country\") \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "result_country.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/score_env_by_country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a0af72-952a-4e1c-9cd5-2590cf249643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moyenne score_composite (aliments sains) par pays (classés par fréquence d’apparition) \n",
    "\n",
    "score_composite_by_country = df_enriched.groupBy(\"country\") \\\n",
    "    .agg(F.avg(\"score_composite\").alias(\"avg_score_composite\"))\n",
    "\n",
    "result_composite_country = score_composite_by_country.join(country_freq, on=\"country\") \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "result_composite_country.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/score_composite_by_country\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2cd37-d351-4ad7-b4be-5a7b3aad6b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏷️ Moyenne score_env_composite_flexible par marque (classées par fréquence)\n",
    "\n",
    "brand_freq = df_enriched.groupBy(\"brands\").count()\n",
    "\n",
    "score_by_brand = df_enriched.groupBy(\"brands\") \\\n",
    "    .agg(F.avg(\"score_env_composite_flexible\").alias(\"avg_score_env_composite_flexible\"))\n",
    "\n",
    "result_brand = score_by_brand.join(brand_freq, on=\"brands\") \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "result_brand.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/score_env_by_brand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e8c34-5fd8-4fc5-8c3f-bd310fb92421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏷️ Moyenne score_composite par marque (classées par fréquence)\n",
    "\n",
    "score_composite_by_brand = df_enriched.groupBy(\"brands\") \\\n",
    "    .agg(F.avg(\"score_composite\").alias(\"avg_score_composite\"))\n",
    "\n",
    "result_composite_brand = score_composite_by_brand.join(brand_freq, on=\"brands\") \\\n",
    "    .orderBy(F.desc(\"count\"))\n",
    "\n",
    "result_composite_brand.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/score_composite_by_brand\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538c60f-1716-45b6-8054-8aed4f53660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg , trim, lower\n",
    "\n",
    "# 🧱 Étape 1 : Base pour les moyennes\n",
    "df_base = df_enriched.select(\n",
    "    col(\"country\"),\n",
    "    col(\"brands\"),\n",
    "    col(\"score_env_composite_flexible\").cast(\"double\").alias(\"score_env_composite_flexible\"),\n",
    "    col(\"score_composite\").cast(\"double\").alias(\"score_composite\"),\n",
    "    col(\"energy-kcal_100g\").cast(\"double\").alias(\"energy_kcal_100g\")\n",
    ")\n",
    "df_base.createOrReplaceTempView(\"df_base\")\n",
    "\n",
    "# 📊 Étape 2 : CUBE des moyennes\n",
    "query_cube = \"\"\"\n",
    "SELECT\n",
    "    country,\n",
    "    brands,\n",
    "    AVG(score_env_composite_flexible) AS avg_env_score,\n",
    "    AVG(score_composite) AS avg_composite_score,\n",
    "    AVG(energy_kcal_100g) AS avg_kcal,\n",
    "    GROUPING(country) AS grouping_country,\n",
    "    GROUPING(brands) AS grouping_brands,\n",
    "    GROUPING_ID(country, brands) AS grouping_id\n",
    "FROM df_base\n",
    "GROUP BY CUBE(country, brands)\n",
    "\"\"\"\n",
    "df_grouped = spark.sql(query_cube)\n",
    "\n",
    "# ➕ Étape 3 : Proportions nutritionnelles\n",
    "df_flags = df_enriched.select(\n",
    "    col(\"country\"), col(\"brands\"),\n",
    "    col(\"is_vegan\").cast(\"int\"),\n",
    "    col(\"is_vegetarian\").cast(\"int\"),\n",
    "    col(\"is_sans_sucre\").cast(\"int\"),\n",
    "    col(\"is_protein_plus\").cast(\"int\"),\n",
    "    col(\"is_light\").cast(\"int\"),\n",
    "    col(\"is_ultra_transformed\").cast(\"int\")\n",
    ")\n",
    "\n",
    "df_props = df_flags.groupBy(\"country\", \"brands\").agg(\n",
    "    avg(\"is_vegan\").alias(\"prop_vegan\"),\n",
    "    avg(\"is_vegetarian\").alias(\"prop_vegetarian\"),\n",
    "    avg(\"is_sans_sucre\").alias(\"prop_sans_sucre\"),\n",
    "    avg(\"is_protein_plus\").alias(\"prop_protein_plus\"),\n",
    "    avg(\"is_light\").alias(\"prop_light\"),\n",
    "    avg(\"is_ultra_transformed\").alias(\"prop_ultra_transformed\")\n",
    ")\n",
    "\n",
    "# 🎯 Étape 4 : Booléens \"majoritaires\"\n",
    "threshold = 0.5\n",
    "df_props = df_props \\\n",
    "    .withColumn(\"is_majority_vegan\", col(\"prop_vegan\") >= threshold) \\\n",
    "    .withColumn(\"is_majority_vegetarian\", col(\"prop_vegetarian\") >= threshold) \\\n",
    "    .withColumn(\"is_majority_sans_sucre\", col(\"prop_sans_sucre\") >= threshold) \\\n",
    "    .withColumn(\"is_majority_protein_plus\", col(\"prop_protein_plus\") >= threshold) \\\n",
    "    .withColumn(\"is_majority_light\", col(\"prop_light\") >= threshold) \\\n",
    "    .withColumn(\"is_majority_ultra_transformed\", col(\"prop_ultra_transformed\") >= threshold)\n",
    "\n",
    "# 🔗 Étape 5 : Jointure avec le CUBE\n",
    "df_final = df_grouped.join(df_props, on=[\"country\", \"brands\"], how=\"left\")\n",
    "\n",
    "# 💾 Étape 6 : Export\n",
    "df_final.coalesce(1) \\\n",
    "    .write.option(\"header\", \"true\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .csv(\"../data/viz/cube_agg_country_brand_scores_enriched\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
